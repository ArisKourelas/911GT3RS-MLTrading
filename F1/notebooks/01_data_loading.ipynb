{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "load_data_code = '''\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_csv(filename, subfolder='raw'):\n",
        "    \"\"\"\n",
        "    Load a CSV from the data directory.\n",
        "\n",
        "    Args:\n",
        "        filename (str): Name of the file (e.g., 'spy_data.csv')\n",
        "        subfolder (str): Subdirectory under /data (e.g., 'raw', 'processed')\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Loaded DataFrame\n",
        "    \"\"\"\n",
        "    path = os.path.join(\"data\", subfolder, filename)\n",
        "    return pd.read_csv(path)\n",
        "'''\n",
        "\n",
        "with open(\"SPY_Model/utils/load_data.py\", \"w\") as f:\n",
        "    f.write(load_data_code)\n",
        "\n",
        "print(\"load_data.py restored.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "load_data.py restored.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1746921474555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Current working directory\n",
        "base_dir = \"SPY_Model\"\n",
        "source_dir = base_dir\n",
        "target_dir = os.path.join(base_dir, \"data\", \"raw\")\n",
        "\n",
        "# Make sure the target exists\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Move all CSVs that start with 'SPY_5min' to data/raw/\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.startswith(\"SPY_5min\") and filename.endswith(\".csv\"):\n",
        "        src = os.path.join(source_dir, filename)\n",
        "        dst = os.path.join(target_dir, filename)\n",
        "        print(f\"Moving {filename} -> data/raw/\")\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "print(\"All files moved successfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "All files moved successfully.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1746921474787
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/arisgkourelas1/code/Users/arisgkourelas/SPY_Model/notebooks\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1746921475005
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Base dir is two levels up from current notebooks folder\n",
        "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "\n",
        "# Correct paths\n",
        "source_dir = os.path.join(base_dir, \"SPY_Model\")\n",
        "target_dir = os.path.join(base_dir, \"SPY_Model/data/raw\")\n",
        "\n",
        "# Make sure target exists\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "# Move all SPY csvs\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.startswith(\"SPY_5min\") and filename.endswith(\".csv\"):\n",
        "        src = os.path.join(source_dir, filename)\n",
        "        dst = os.path.join(target_dir, filename)\n",
        "        print(f\"Moving {filename} -> data/raw/\")\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "print(\"All files moved successfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "All files moved successfully.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1746921475189
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Print current working directory\n",
        "print(\"Current notebook directory:\\n\", os.getcwd(), \"\\n\")\n",
        "\n",
        "# Walk from the current notebookâ€™s root\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for name in dirs + files:\n",
        "        print(os.path.join(root, name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current notebook directory:\n /mnt/batch/tasks/shared/LS_root/mounts/clusters/arisgkourelas1/code/Users/arisgkourelas/SPY_Model/notebooks \n\n./.ipynb_aml_checkpoints\n./SPY_Model\n./.amlignore\n./.amlignore.amltmp\n./01_data_loading.ipynb\n./01_data_loading.ipynb.amltmp\n./935_model.ipynb\n./935_model.ipynb.amltmp\n./spy_classifier.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-23-55-59Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-45-34Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-46-23Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-50-27Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-6-9Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-7-2-30Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-9-4-33Z.ipynb\n./.ipynb_aml_checkpoints/935_model-checkpoint2025-4-10-23-55-57Z.ipynb\n./.ipynb_aml_checkpoints/935_model-checkpoint2025-4-10-8-16-33Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-3-2-25-15Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-10-49-37Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-5-48-42Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-8-4-40Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-9-28-53Z.ipynb\n./SPY_Model/data\n./SPY_Model/models\n./SPY_Model/notebooks\n./SPY_Model/outputs\n./SPY_Model/utils\n./SPY_Model/data/features\n./SPY_Model/data/processed\n./SPY_Model/data/raw\n./SPY_Model/models/ensemble_outputs\n./SPY_Model/models/saved_models\n./SPY_Model/outputs/reports\n./SPY_Model/utils/load_data.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1746921475434
        },
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Show working directory\n",
        "print(\"\\n--- Current Working Directory ---\")\n",
        "print(os.getcwd())\n",
        "\n",
        "# Walk through current folder and print all subfolders and files\n",
        "print(\"\\n--- Full Folder Tree from Current Directory ---\")\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for name in dirs + files:\n",
        "        print(os.path.join(root, name))\n",
        "\n",
        "# Check key file path manually\n",
        "print(\"\\n--- Checking Key File Existence ---\")\n",
        "csv_path = os.path.join(\"..\", \"data\", \"raw\", \"SPY_5min_2020_05.csv\")\n",
        "print(\"Looking for file at:\", csv_path)\n",
        "print(\"Exists:\", os.path.isfile(csv_path))\n",
        "\n",
        "# Try loading the CSV directly using pandas\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(\"\\n--- CSV File Loaded Successfully ---\")\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(\"\\n--- CSV Load Failed ---\")\n",
        "    print(repr(e))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--- Current Working Directory ---\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/arisgkourelas1/code/Users/arisgkourelas/SPY_Model/notebooks\n\n--- Full Folder Tree from Current Directory ---\n./.ipynb_aml_checkpoints\n./SPY_Model\n./.amlignore\n./.amlignore.amltmp\n./01_data_loading.ipynb\n./01_data_loading.ipynb.amltmp\n./935_model.ipynb\n./935_model.ipynb.amltmp\n./spy_classifier.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-23-55-59Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-45-34Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-46-23Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-50-27Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-5-6-9Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-7-2-30Z.ipynb\n./.ipynb_aml_checkpoints/01_data_loading-checkpoint2025-4-10-9-4-33Z.ipynb\n./.ipynb_aml_checkpoints/935_model-checkpoint2025-4-10-23-55-57Z.ipynb\n./.ipynb_aml_checkpoints/935_model-checkpoint2025-4-10-8-16-33Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-3-2-25-15Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-10-49-37Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-5-48-42Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-8-4-40Z.ipynb\n./.ipynb_aml_checkpoints/spy_classifier-checkpoint2025-4-9-9-28-53Z.ipynb\n./SPY_Model/data\n./SPY_Model/models\n./SPY_Model/notebooks\n./SPY_Model/outputs\n./SPY_Model/utils\n./SPY_Model/data/features\n./SPY_Model/data/processed\n./SPY_Model/data/raw\n./SPY_Model/models/ensemble_outputs\n./SPY_Model/models/saved_models\n./SPY_Model/outputs/reports\n./SPY_Model/utils/load_data.py\n\n--- Checking Key File Existence ---\nLooking for file at: ../data/raw/SPY_5min_2020_05.csv\nExists: True\n\n--- CSV File Loaded Successfully ---\n   volume        vw    open   close    high     low            timestamp  \\\n0  4927.0  294.0346  293.83  293.96  294.34  293.83  2020-05-11 08:00:00   \n1  7420.0  293.9817  294.01  293.92  294.04  293.92  2020-05-11 08:05:00   \n2  3675.0  293.8851  293.95  293.60  293.98  293.59  2020-05-11 08:10:00   \n3  6945.0  293.5993  293.60  293.67  293.69  293.57  2020-05-11 08:15:00   \n4  4252.0  293.7026  293.68  293.55  293.76  293.55  2020-05-11 08:20:00   \n\n   trades  \n0      48  \n1      46  \n2      35  \n3      35  \n4      45  \n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1746921478502
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Construct the absolute path.\n",
        "abs_path = os.path.abspath(os.path.join(\"..\", \"data\", \"raw\", \"SPY_5min_2020_05.csv\"))\n",
        "print(\"Absolute file path:\", abs_path)\n",
        "\n",
        "# Try loading the CSV directly using the absolute path.\n",
        "try:\n",
        "    df = pd.read_csv(abs_path)\n",
        "    print(\"CSV Loaded Successfully!\")\n",
        "    print(df.head())\n",
        "except Exception as e:\n",
        "    print(\"Error loading CSV:\", repr(e))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Absolute file path: /mnt/batch/tasks/shared/LS_root/mounts/clusters/arisgkourelas1/code/Users/arisgkourelas/SPY_Model/data/raw/SPY_5min_2020_05.csv\nCSV Loaded Successfully!\n   volume        vw    open   close    high     low            timestamp  \\\n0  4927.0  294.0346  293.83  293.96  294.34  293.83  2020-05-11 08:00:00   \n1  7420.0  293.9817  294.01  293.92  294.04  293.92  2020-05-11 08:05:00   \n2  3675.0  293.8851  293.95  293.60  293.98  293.59  2020-05-11 08:10:00   \n3  6945.0  293.5993  293.60  293.67  293.69  293.57  2020-05-11 08:15:00   \n4  4252.0  293.7026  293.68  293.55  293.76  293.55  2020-05-11 08:20:00   \n\n   trades  \n0      48  \n1      46  \n2      35  \n3      35  \n4      45  \n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1746921478660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add full path to the utils folder\n",
        "sys.path.append(os.path.abspath(\"../utils\"))\n",
        "\n",
        "from load_data import load_csv"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1746921478783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from load_data import load_csv\n",
        "\n",
        "# Define raw data folder path relative to this notebook\n",
        "raw_dir = \"../data/raw\"\n",
        "\n",
        "# List and sort all SPY CSV files\n",
        "all_files = sorted(f for f in os.listdir(raw_dir) if f.startswith(\"SPY_5min\") and f.endswith(\".csv\"))\n",
        "\n",
        "# Load and combine\n",
        "df_list = [load_csv(f, subfolder=raw_dir) for f in all_files]\n",
        "full_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(\"Combined full_df shape:\", full_df.shape)\n",
        "full_df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Combined full_df shape: (487214, 8)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "   volume        vw    open   close    high     low            timestamp  \\\n0  4927.0  294.0346  293.83  293.96  294.34  293.83  2020-05-11 08:00:00   \n1  7420.0  293.9817  294.01  293.92  294.04  293.92  2020-05-11 08:05:00   \n2  3675.0  293.8851  293.95  293.60  293.98  293.59  2020-05-11 08:10:00   \n3  6945.0  293.5993  293.60  293.67  293.69  293.57  2020-05-11 08:15:00   \n4  4252.0  293.7026  293.68  293.55  293.76  293.55  2020-05-11 08:20:00   \n\n   trades  \n0      48  \n1      46  \n2      35  \n3      35  \n4      45  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>volume</th>\n      <th>vw</th>\n      <th>open</th>\n      <th>close</th>\n      <th>high</th>\n      <th>low</th>\n      <th>timestamp</th>\n      <th>trades</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4927.0</td>\n      <td>294.0346</td>\n      <td>293.83</td>\n      <td>293.96</td>\n      <td>294.34</td>\n      <td>293.83</td>\n      <td>2020-05-11 08:00:00</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7420.0</td>\n      <td>293.9817</td>\n      <td>294.01</td>\n      <td>293.92</td>\n      <td>294.04</td>\n      <td>293.92</td>\n      <td>2020-05-11 08:05:00</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3675.0</td>\n      <td>293.8851</td>\n      <td>293.95</td>\n      <td>293.60</td>\n      <td>293.98</td>\n      <td>293.59</td>\n      <td>2020-05-11 08:10:00</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6945.0</td>\n      <td>293.5993</td>\n      <td>293.60</td>\n      <td>293.67</td>\n      <td>293.69</td>\n      <td>293.57</td>\n      <td>2020-05-11 08:15:00</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4252.0</td>\n      <td>293.7026</td>\n      <td>293.68</td>\n      <td>293.55</td>\n      <td>293.76</td>\n      <td>293.55</td>\n      <td>2020-05-11 08:20:00</td>\n      <td>45</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1746921480678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save combined data to processed folder\n",
        "output_path = \"../data/processed/full_SPY_data.csv\"\n",
        "full_df.to_csv(output_path, index=False)\n",
        "print(f\"Saved to: {output_path}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Saved to: ../data/processed/full_SPY_data.csv\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1746921483196
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}