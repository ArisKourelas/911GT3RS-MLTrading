{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Block 1: Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Setup complete.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Setup complete.\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1746792873135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2: Load and concatenate CSV data\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Replace with the folder where your CSVs are stored\n",
        "data_folder = \".\"\n",
        "\n",
        "# Grab all CSVs in that folder\n",
        "csv_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
        "\n",
        "# Read and concatenate all CSVs\n",
        "all_data = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
        "\n",
        "# Convert timestamp to datetime\n",
        "all_data[\"timestamp\"] = pd.to_datetime(all_data[\"timestamp\"])\n",
        "\n",
        "df = add_technical_indicators(df)\n",
        "\n",
        "# Sort just in case\n",
        "all_data = all_data.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "print(\"Data loaded:\", all_data[\"timestamp\"].min(), \"to\", all_data[\"timestamp\"].max())"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'close_935'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'close_935'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[68], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert timestamp to datetime\u001b[39;00m\n\u001b[1;32m     15\u001b[0m all_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(all_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43madd_technical_indicators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Sort just in case\u001b[39;00m\n\u001b[1;32m     20\u001b[0m all_data \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[65], line 5\u001b[0m, in \u001b[0;36madd_technical_indicators\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_technical_indicators\u001b[39m(df):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# RSI\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclose_935\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdiff()\n\u001b[1;32m      6\u001b[0m     gain \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mwhere(delta \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mdelta\u001b[38;5;241m.\u001b[39mwhere(delta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'close_935'"
          ]
        }
      ],
      "execution_count": 68,
      "metadata": {
        "gather": {
          "logged": 1746793592484
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 3 Create a new DataFrame to hold daily rows\n",
        "daily_rows = []\n",
        "\n",
        "# Group by date\n",
        "for date, group in all_data.groupby(all_data[\"timestamp\"].dt.date):\n",
        "    # Get all times for this day\n",
        "    group = group.sort_values(\"timestamp\")\n",
        "    \n",
        "    # Extract 9:30 and 9:35 data\n",
        "    open_row = group[group[\"timestamp\"].dt.time == pd.to_datetime(\"09:30\").time()]\n",
        "    after_5min_row = group[group[\"timestamp\"].dt.time == pd.to_datetime(\"09:35\").time()]\n",
        "    \n",
        "    # Only include rows where both exist\n",
        "    if not open_row.empty and not after_5min_row.empty:\n",
        "        row = {\n",
        "            \"date\": pd.to_datetime(date),\n",
        "            \"close_930\": open_row.iloc[0][\"close\"],\n",
        "            \"close_935\": after_5min_row.iloc[0][\"close\"],\n",
        "            \"volume\": after_5min_row.iloc[0][\"volume\"]\n",
        "        }\n",
        "        daily_rows.append(row)\n",
        "\n",
        "# Create model_df\n",
        "model_df = pd.DataFrame(daily_rows)\n",
        "\n",
        "# Target label: did it go up?\n",
        "model_df[\"went_up\"] = (model_df[\"close_935\"] > model_df[\"close_930\"]).astype(int)\n",
        "\n",
        "# Preview\n",
        "print(model_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "        date  close_930  close_935   volume  went_up\n0 2020-05-11     291.85     291.94   4901.0        1\n1 2020-05-13     286.14     286.39  12385.0        1\n2 2020-05-14     281.69     281.74   4600.0        1\n3 2020-05-15     285.72     285.45   3130.0        0\n4 2020-05-18     288.97     289.00  23876.0        1\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1746792881485
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 4: Calendar Features + Target\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "model_df = build_calendar_features(all_data)\n",
        "\n",
        "df = all_data.copy()\n",
        "df[\"date\"] = df[\"timestamp\"].dt.date\n",
        "df[\"time\"] = df[\"timestamp\"].dt.time\n",
        "\n",
        "# Extract 9:30 and 9:35 closes\n",
        "df_930 = df[df[\"timestamp\"].dt.time == pd.to_datetime(\"09:30\").time()]\n",
        "df_935 = df[df[\"timestamp\"].dt.time == pd.to_datetime(\"09:35\").time()]\n",
        "df_930 = df_930.groupby(\"date\")[\"close\"].first().reset_index().rename(columns={\"close\": \"close_930\"})\n",
        "df_935 = df_935.groupby(\"date\")[\"close\"].first().reset_index().rename(columns={\"close\": \"close_935\"})\n",
        "model_df = pd.merge(df_930, df_935, on=\"date\", how=\"inner\")\n",
        "\n",
        "# Calendar features\n",
        "model_df[\"date\"] = pd.to_datetime(model_df[\"date\"])\n",
        "model_df[\"day_of_week\"] = model_df[\"date\"].dt.weekday\n",
        "model_df[\"is_monday\"] = (model_df[\"day_of_week\"] == 0).astype(int)\n",
        "model_df[\"is_friday\"] = (model_df[\"day_of_week\"] == 4).astype(int)\n",
        "model_df[\"month\"] = model_df[\"date\"].dt.month\n",
        "model_df[\"year\"] = model_df[\"date\"].dt.year\n",
        "model_df[\"quarter\"] = model_df[\"date\"].dt.quarter\n",
        "model_df[\"is_month_start\"] = model_df[\"date\"].dt.is_month_start.astype(int)\n",
        "model_df[\"is_month_end\"] = model_df[\"date\"].dt.is_month_end.astype(int)\n",
        "model_df[\"is_quarter_start\"] = model_df[\"date\"].dt.is_quarter_start.astype(int)\n",
        "model_df[\"is_quarter_end\"] = model_df[\"date\"].dt.is_quarter_end.astype(int)\n",
        "\n",
        "# Season encoding\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]: return \"Winter\"\n",
        "    elif month in [3, 4, 5]: return \"Spring\"\n",
        "    elif month in [6, 7, 8]: return \"Summer\"\n",
        "    else: return \"Fall\"\n",
        "model_df[\"season\"] = model_df[\"month\"].apply(get_season)\n",
        "model_df = pd.get_dummies(model_df, columns=[\"season\"], prefix=\"season\")\n",
        "\n",
        "# Holiday awareness\n",
        "cal = USFederalHolidayCalendar()\n",
        "holidays = cal.holidays(start=model_df[\"date\"].min(), end=model_df[\"date\"].max())\n",
        "model_df[\"is_holiday\"] = model_df[\"date\"].isin(holidays).astype(int)\n",
        "model_df[\"prev_day\"] = model_df[\"date\"] - pd.Timedelta(days=1)\n",
        "model_df[\"is_after_holiday\"] = model_df[\"prev_day\"].isin(holidays).astype(int)\n",
        "\n",
        "# First trading day of each month\n",
        "model_df[\"date_only\"] = model_df[\"date\"].dt.date\n",
        "first_of_month = model_df.groupby(model_df[\"date\"].dt.to_period(\"M\"))[\"date\"].min().values\n",
        "model_df[\"is_first_trading_day\"] = model_df[\"date\"].isin(first_of_month).astype(int)\n",
        "\n",
        "# Target\n",
        "model_df[\"went_up\"] = (model_df[\"close_935\"] > model_df[\"close_930\"]).astype(int)\n",
        "\n",
        "# Drop unused\n",
        "model_df.drop(columns=[\"date_only\", \"prev_day\"], inplace=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'build_calendar_features' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[67], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Block 4: Calendar Features + Target\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mholiday\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m USFederalHolidayCalendar\n\u001b[0;32m----> 3\u001b[0m model_df \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_calendar_features\u001b[49m(all_data)\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m all_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_calendar_features' is not defined"
          ]
        }
      ],
      "execution_count": 67,
      "metadata": {
        "gather": {
          "logged": 1746793170452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 6: Add Previous Day Features\n",
        "\n",
        "# Step 1: Create previous day reference\n",
        "model_df[\"prev_day\"] = model_df[\"date\"].shift(1)\n",
        "\n",
        "# Step 2: Create a DataFrame with previous day's open and close\n",
        "df_prev = model_df[[\"date\", \"close_930\"]].copy()\n",
        "df_prev.columns = [\"prev_day\", \"prev_day_open\"]\n",
        "\n",
        "df_prev[\"prev_day_close\"] = model_df[\"close_935\"].shift(1).values\n",
        "\n",
        "# Step 3: Merge previous day data\n",
        "model_df = pd.merge(model_df, df_prev, on=\"prev_day\", how=\"left\")\n",
        "\n",
        "# Step 4: Create previous day return\n",
        "model_df[\"prev_day_return\"] = (\n",
        "    (model_df[\"prev_day_close\"] - model_df[\"prev_day_open\"]) / model_df[\"prev_day_open\"]\n",
        ")\n",
        "\n",
        "# Step 5: Drop early NaNs\n",
        "model_df = model_df.dropna(subset=[\"prev_day_return\"]).reset_index(drop=True)\n",
        "\n",
        "# Confirm columns\n",
        "print(\"Columns after adding prev day features:\", model_df.columns.tolist())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Columns after adding prev day features: ['date', 'close_930', 'close_935', 'day_of_week', 'is_monday', 'is_friday', 'month', 'year', 'quarter', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'went_up', 'prev_day', 'prev_day_open', 'prev_day_close', 'prev_day_return']\n"
        }
      ],
      "execution_count": 64,
      "metadata": {
        "gather": {
          "logged": 1746793018797
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 7: Add Technical Indicators\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    # RSI\n",
        "    delta = df[\"close_935\"].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.rolling(window=14).mean()\n",
        "    avg_loss = loss.rolling(window=14).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    df[\"rsi_14\"] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # SMA and ratios\n",
        "    df[\"sma_5\"] = df[\"close_935\"].rolling(window=5).mean()\n",
        "    df[\"sma_20\"] = df[\"close_935\"].rolling(window=20).mean()\n",
        "    df[\"sma_ratio\"] = df[\"sma_5\"] / df[\"sma_20\"]\n",
        "    df[\"sma_distance\"] = (df[\"close_935\"] - df[\"sma_20\"]) / df[\"sma_20\"]\n",
        "\n",
        "    # Volatility\n",
        "    df[\"prior_volatility\"] = df[\"close_930\"].rolling(window=5).std()\n",
        "\n",
        "    # Bollinger Bands\n",
        "    df[\"bb_middle\"] = df[\"sma_20\"]\n",
        "    df[\"bb_std\"] = df[\"close_935\"].rolling(window=20).std()\n",
        "    df[\"bb_upper\"] = df[\"bb_middle\"] + 2 * df[\"bb_std\"]\n",
        "    df[\"bb_lower\"] = df[\"bb_middle\"] - 2 * df[\"bb_std\"]\n",
        "    df[\"bollinger_width\"] = (df[\"bb_upper\"] - df[\"bb_lower\"]) / df[\"bb_middle\"]\n",
        "    df[\"bollinger_position\"] = (df[\"close_935\"] - df[\"bb_lower\"]) / (df[\"bb_upper\"] - df[\"bb_lower\"])\n",
        "\n",
        "    # MACD\n",
        "    ema12 = df[\"close_935\"].ewm(span=12, adjust=False).mean()\n",
        "    ema26 = df[\"close_935\"].ewm(span=26, adjust=False).mean()\n",
        "    df[\"macd\"] = ema12 - ema26\n",
        "    df[\"macd_signal\"] = df[\"macd\"].ewm(span=9, adjust=False).mean()\n",
        "    df[\"macd_diff\"] = df[\"macd\"] - df[\"macd_signal\"]\n",
        "\n",
        "    # Overnight gap\n",
        "    df[\"overnight_gap\"] = (df[\"close_930\"] - df[\"prev_day_close\"]) / df[\"prev_day_close\"]\n",
        "\n",
        "    # Previous day movement\n",
        "    df[\"prev_day_change\"] = (df[\"prev_day_close\"] - df[\"prev_day_open\"]) / df[\"prev_day_open\"]\n",
        "    df[\"prev_day_range_pct\"] = (df[\"prev_day_close\"] - df[\"prev_day_open\"]).abs() / df[\"prev_day_open\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "model_df = add_technical_indicators(model_df)\n",
        "model_df = model_df.dropna().reset_index(drop=True)\n",
        "\n",
        "print(\"Technical indicators added. Columns now:\", model_df.columns.tolist())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Technical indicators added. Columns now: ['date', 'close_930', 'close_935', 'day_of_week', 'is_monday', 'is_friday', 'month', 'year', 'quarter', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'season_Fall', 'season_Spring', 'season_Summer', 'season_Winter', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'went_up', 'prev_day', 'prev_day_open', 'prev_day_close', 'prev_day_return', 'rsi_14', 'sma_5', 'sma_20', 'sma_ratio', 'sma_distance', 'prior_volatility', 'bb_middle', 'bb_std', 'bb_upper', 'bb_lower', 'bollinger_width', 'bollinger_position', 'macd', 'macd_signal', 'macd_diff', 'overnight_gap', 'prev_day_change', 'prev_day_range_pct']\n"
        }
      ],
      "execution_count": 65,
      "metadata": {
        "gather": {
          "logged": 1746793024980
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "data_folder = \".\"  # or your actual folder name\n",
        "csv_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
        "\n",
        "# Read and concatenate all CSVs\n",
        "full_df = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
        "\n",
        "# Convert timestamp\n",
        "full_df[\"timestamp\"] = pd.to_datetime(full_df[\"timestamp\"])\n",
        "full_df[\"date\"] = full_df[\"timestamp\"].dt.date\n",
        "full_df[\"time\"] = full_df[\"timestamp\"].dt.strftime(\"%H:%M\")\n",
        "\n",
        "# Filter to keep only 9:30 and 9:35 rows\n",
        "full_df = full_df[full_df[\"time\"].isin([\"09:30\", \"09:35\"])].reset_index(drop=True)\n",
        "\n",
        "print(\"Filtered to 9:30 and 9:35 AM rows only:\", full_df.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Filtered to 9:30 and 9:35 AM rows only: (4856, 10)\n"
        }
      ],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1746792905369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_df[\"date\"] = pd.to_datetime(model_df[\"date\"])\n",
        "full_df[\"date\"] = pd.to_datetime(full_df[\"date\"])"
      ],
      "outputs": [],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1746792906941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 8: Add Volume-Based Features\n",
        "\n",
        "# Step 1: Compute volume rolling stats using only 09:35 rows\n",
        "volume_df = full_df[full_df[\"time\"] == \"09:35\"].copy()\n",
        "volume_df = volume_df.sort_values(\"timestamp\")  # make sure it's sorted\n",
        "volume_df[\"volume_5day_avg\"] = volume_df[\"volume\"].rolling(window=5).mean()\n",
        "volume_df[\"volume_5day_ratio\"] = volume_df[\"volume\"] / volume_df[\"volume_5day_avg\"]\n",
        "\n",
        "# Step 2: Now this is our model_df (the one weâ€™ll use from now on)\n",
        "model_df = volume_df.reset_index(drop=True)\n",
        "\n",
        "# Step 3: Drop early NaNs due to rolling window\n",
        "model_df = model_df.dropna(subset=[\"volume_5day_avg\", \"volume_5day_ratio\"])\n",
        "\n",
        "print(\"Volume features added. Columns now:\", model_df.columns.tolist())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Volume features added. Columns now: ['volume', 'vw', 'open', 'close', 'high', 'low', 'timestamp', 'trades', 'date', 'time', 'volume_5day_avg', 'volume_5day_ratio']\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1746792909040
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 9: Merge engineered features into 09:35 filtered model_df\n",
        "\n",
        "# Step 1: Define all engineered columns we want to include\n",
        "calendar_and_tech_cols = [\n",
        "    \"date\", \"close_930\", \"close_935\", \"day_of_week\", \"is_monday\", \"is_friday\",\n",
        "    \"month\", \"year\", \"quarter\", \"is_month_start\", \"is_month_end\",\n",
        "    \"is_quarter_start\", \"is_quarter_end\", \"season_Winter\", \"season_Spring\",\n",
        "    \"season_Summer\", \"season_Fall\", \"is_holiday\", \"is_after_holiday\",\n",
        "    \"is_first_trading_day\", \"went_up\", \"prev_day\", \"prev_day_open\",\n",
        "    \"prev_day_close\", \"prev_day_return\", \"rsi_14\", \"sma_5\", \"sma_20\",\n",
        "    \"sma_ratio\", \"sma_distance\", \"prior_volatility\", \"bb_middle\", \"bb_std\",\n",
        "    \"bb_upper\", \"bb_lower\", \"bollinger_width\", \"bollinger_position\",\n",
        "    \"macd\", \"macd_signal\", \"macd_diff\", \"overnight_gap\",\n",
        "    \"prev_day_change\", \"prev_day_range_pct\"\n",
        "]\n",
        "\n",
        "# Step 2: Merge the engineered feature data from `df` into `model_df` (which is only 9:35 rows)\n",
        "model_df = pd.merge(\n",
        "    model_df,\n",
        "    df[calendar_and_tech_cols],\n",
        "    on=\"date\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Step 3: Drop any rows with missing values\n",
        "model_df = model_df.dropna().reset_index(drop=True)\n",
        "\n",
        "# Check structure\n",
        "print(\"Merged feature-rich model_df shape:\", model_df.shape)\n",
        "print(\"Columns now:\", model_df.columns.tolist())"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['close_930', 'close_935', 'day_of_week', 'is_monday', 'is_friday', 'month', 'year', 'quarter', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'season_Winter', 'season_Spring', 'season_Summer', 'season_Fall', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'went_up', 'prev_day', 'prev_day_open', 'prev_day_close', 'prev_day_return', 'rsi_14', 'sma_5', 'sma_20', 'sma_ratio', 'sma_distance', 'prior_volatility', 'bb_middle', 'bb_std', 'bb_upper', 'bb_lower', 'bollinger_width', 'bollinger_position', 'macd', 'macd_signal', 'macd_diff', 'overnight_gap', 'prev_day_change', 'prev_day_range_pct'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 20\u001b[0m\n\u001b[1;32m      4\u001b[0m calendar_and_tech_cols \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_930\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_935\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_monday\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_friday\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_month_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_month_end\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_day_change\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_day_range_pct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 2: Merge the engineered feature data from `df` into `model_df` (which is only 9:35 rows)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m     19\u001b[0m     model_df,\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcalendar_and_tech_cols\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     21\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Step 3: Drop any rows with missing values\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model_df \u001b[38;5;241m=\u001b[39m model_df\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['close_930', 'close_935', 'day_of_week', 'is_monday', 'is_friday', 'month', 'year', 'quarter', 'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end', 'season_Winter', 'season_Spring', 'season_Summer', 'season_Fall', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'went_up', 'prev_day', 'prev_day_open', 'prev_day_close', 'prev_day_return', 'rsi_14', 'sma_5', 'sma_20', 'sma_ratio', 'sma_distance', 'prior_volatility', 'bb_middle', 'bb_std', 'bb_upper', 'bb_lower', 'bollinger_width', 'bollinger_position', 'macd', 'macd_signal', 'macd_diff', 'overnight_gap', 'prev_day_change', 'prev_day_range_pct'] not in index\""
          ]
        }
      ],
      "execution_count": 66,
      "metadata": {
        "gather": {
          "logged": 1746793041613
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Choose refined feature set\n",
        "refined_features = [\n",
        "    \"is_quarter_start\", \"is_month_start\", \"is_quarter_end\", \"is_month_end\",\n",
        "    \"day_of_week\", \"month\", \"year\", \"season_Winter\", \"season_Spring\",\n",
        "    \"season_Summer\", \"season_Fall\", \"is_holiday\", \"is_after_holiday\",\n",
        "    \"is_first_trading_day\", \"overnight_gap\", \"sma_ratio\", \"sma_distance\",\n",
        "    \"prior_volatility\", \"rsi_14\", \"bollinger_width\", \"bollinger_position\",\n",
        "    \"macd_diff\", \"prev_day_change\", \"prev_day_range_pct\", \"volume_5day_ratio\"\n",
        "]\n",
        "\n",
        "# Step 2: Filter model_df to include only selected features + target\n",
        "model_df_final = model_df[refined_features + [\"went_up\"]].dropna()\n",
        "\n",
        "# Step 3: Create X (features) and y (target)\n",
        "X = model_df_final[refined_features]\n",
        "y = model_df_final[\"went_up\"]\n",
        "\n",
        "# Step 4: Train/test split (by date order, 80/20)\n",
        "split_index = int(len(model_df_final) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
        "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
        "\n",
        "# Preview\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['is_quarter_start', 'is_month_start', 'is_quarter_end', 'is_month_end', 'day_of_week', 'month', 'year', 'season_Winter', 'season_Spring', 'season_Summer', 'season_Fall', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'overnight_gap', 'sma_ratio', 'sma_distance', 'prior_volatility', 'rsi_14', 'bollinger_width', 'bollinger_position', 'macd_diff', 'prev_day_change', 'prev_day_range_pct', 'went_up'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m refined_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_quarter_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_month_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_quarter_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_month_end\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday_of_week\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason_Winter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason_Spring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacd_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_day_change\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_day_range_pct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume_5day_ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 2: Filter model_df to include only selected features + target\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model_df_final \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrefined_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwent_up\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Step 3: Create X (features) and y (target)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m model_df_final[refined_features]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['is_quarter_start', 'is_month_start', 'is_quarter_end', 'is_month_end', 'day_of_week', 'month', 'year', 'season_Winter', 'season_Spring', 'season_Summer', 'season_Fall', 'is_holiday', 'is_after_holiday', 'is_first_trading_day', 'overnight_gap', 'sma_ratio', 'sma_distance', 'prior_volatility', 'rsi_14', 'bollinger_width', 'bollinger_position', 'macd_diff', 'prev_day_change', 'prev_day_range_pct', 'went_up'] not in index\""
          ]
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1746792777461
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}